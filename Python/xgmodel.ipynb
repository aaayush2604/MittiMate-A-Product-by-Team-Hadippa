{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.1-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\python311\\lib\\site-packages (from scikit-learn) (1.26.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\aayus\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn) (1.12.0)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.5.1-cp311-cp311-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/11.0 MB 985.5 kB/s eta 0:00:11\n",
      "   - -------------------------------------- 0.5/11.0 MB 985.5 kB/s eta 0:00:11\n",
      "   -- ------------------------------------- 0.8/11.0 MB 931.2 kB/s eta 0:00:11\n",
      "   --- ------------------------------------ 1.0/11.0 MB 1.0 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 1.3/11.0 MB 958.5 kB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 1.6/11.0 MB 987.0 kB/s eta 0:00:10\n",
      "   ------ --------------------------------- 1.8/11.0 MB 1.0 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 2.1/11.0 MB 1.0 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 2.1/11.0 MB 1.0 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 2.4/11.0 MB 1.0 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 2.6/11.0 MB 1.0 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 2.6/11.0 MB 1.0 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 2.9/11.0 MB 964.1 kB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 3.1/11.0 MB 966.0 kB/s eta 0:00:09\n",
      "   ------------ --------------------------- 3.4/11.0 MB 972.4 kB/s eta 0:00:08\n",
      "   ------------ --------------------------- 3.4/11.0 MB 972.4 kB/s eta 0:00:08\n",
      "   ------------- -------------------------- 3.7/11.0 MB 960.8 kB/s eta 0:00:08\n",
      "   -------------- ------------------------- 3.9/11.0 MB 966.6 kB/s eta 0:00:08\n",
      "   --------------- ------------------------ 4.2/11.0 MB 967.8 kB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 4.5/11.0 MB 976.1 kB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 4.5/11.0 MB 976.1 kB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 4.7/11.0 MB 973.4 kB/s eta 0:00:07\n",
      "   ------------------ --------------------- 5.0/11.0 MB 980.4 kB/s eta 0:00:07\n",
      "   ------------------- -------------------- 5.2/11.0 MB 980.8 kB/s eta 0:00:06\n",
      "   -------------------- ------------------- 5.5/11.0 MB 984.0 kB/s eta 0:00:06\n",
      "   -------------------- ------------------- 5.8/11.0 MB 984.1 kB/s eta 0:00:06\n",
      "   -------------------- ------------------- 5.8/11.0 MB 984.1 kB/s eta 0:00:06\n",
      "   --------------------- ------------------ 6.0/11.0 MB 986.9 kB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 6.3/11.0 MB 986.8 kB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 6.6/11.0 MB 982.1 kB/s eta 0:00:05\n",
      "   ------------------------ --------------- 6.8/11.0 MB 984.6 kB/s eta 0:00:05\n",
      "   ------------------------ --------------- 6.8/11.0 MB 984.6 kB/s eta 0:00:05\n",
      "   ------------------------- -------------- 7.1/11.0 MB 969.4 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 7.3/11.0 MB 972.1 kB/s eta 0:00:04\n",
      "   -------------------------- ------------- 7.3/11.0 MB 972.1 kB/s eta 0:00:04\n",
      "   --------------------------- ------------ 7.6/11.0 MB 960.6 kB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 7.9/11.0 MB 963.4 kB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 7.9/11.0 MB 963.4 kB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 8.1/11.0 MB 964.2 kB/s eta 0:00:03\n",
      "   ------------------------------ --------- 8.4/11.0 MB 959.6 kB/s eta 0:00:03\n",
      "   ------------------------------ --------- 8.4/11.0 MB 959.6 kB/s eta 0:00:03\n",
      "   ------------------------------- -------- 8.7/11.0 MB 956.9 kB/s eta 0:00:03\n",
      "   -------------------------------- ------- 8.9/11.0 MB 961.2 kB/s eta 0:00:03\n",
      "   --------------------------------- ------ 9.2/11.0 MB 961.9 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 9.4/11.0 MB 957.9 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 9.4/11.0 MB 957.9 kB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 9.7/11.0 MB 958.7 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 10.0/11.0 MB 959.4 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 10.2/11.0 MB 963.0 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.5/11.0 MB 963.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------  10.7/11.0 MB 969.7 kB/s eta 0:00:01\n",
      "   ---------------------------------------  10.7/11.0 MB 969.7 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 969.6 kB/s eta 0:00:00\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.1 threadpoolctl-3.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ (C:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~~p (C:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (C:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~~p (C:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (C:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~~p (C:\\Python311\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OneHotEncoder, LabelEncoder\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Crop and fertilizer dataset.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# One-hot encoding for 'District_Name' and 'Soil_color' columns\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "X_encoded = encoder.fit_transform(dataset[['District_Name', 'Soil_color']])\n",
    "\n",
    "# Combine with numerical features\n",
    "X = dataset[['Nitrogen', 'Phosphorus', 'Potassium', 'pH', 'Rainfall', 'Temperature']]\n",
    "X = pd.concat([X, pd.DataFrame(X_encoded.toarray())], axis=1)\n",
    "\n",
    "# Convert column names to strings to avoid type error\n",
    "X.columns = X.columns.astype(str)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(dataset['Fertilizer'])\n",
    "for code, class_name in enumerate(label_encoder.classes_):\n",
    "    print(f\"Code {code} is mapped to class '{class_name}'\")\n",
    "\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42, shuffle=True)\n",
    "\n",
    "# Initialize XGBoost Classifier with tuned parameters\n",
    "model_crop = XGBClassifier(\n",
    "    random_state=42,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='mlogloss',\n",
    "    learning_rate=0.1,  # Adjust learning rate\n",
    "    n_estimators=1000,   # Adjust number of trees  # Adjust minimum child weight\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model_crop.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on validation data\n",
    "y_val_pred = model_crop.predict(X_val)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "val_precision = precision_score(y_val, y_val_pred, average='weighted')\n",
    "val_recall = recall_score(y_val, y_val_pred, average='weighted')\n",
    "val_f1 = f1_score(y_val, y_val_pred, average='weighted')\n",
    "\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "print(\"Validation Precision:\", val_precision)\n",
    "print(\"Validation Recall:\", val_recall)\n",
    "print(\"Validation F1 Score:\", val_f1)\n",
    "print(\"\\nValidation Classification Report:\\n\", classification_report(y_val, y_val_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model_crop.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_precision = precision_score(y_test, y_test_pred, average='weighted')\n",
    "test_recall = recall_score(y_test, y_test_pred, average='weighted')\n",
    "test_f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Test Precision:\", test_precision)\n",
    "print(\"Test Recall:\", test_recall)\n",
    "print(\"Test F1 Score:\", test_f1)\n",
    "print(\"\\nTest Classification Report:\\n\", classification_report(y_test, y_test_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
